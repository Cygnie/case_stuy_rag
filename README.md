# NTT DATA RAG API - Hybrid Search with LangGraph

Production-ready RAG (Retrieval Augmented Generation) system with async architecture:

- **Hybrid Search**: Dense (Gemini) + Sparse (FastEmbed BM25) + RRF Fusion
- **Auto Year Extraction**: LLM automatically extracts years from questions
- **Async Architecture**: Non-blocking requests, high concurrency
- **Lifespan DI**: Singleton services, initialized once at startup
- **Service Layer**: Clean separation of business logic

## ğŸ¯ Features

| Feature | Description |
|---------|-------------|
| âœ… Hybrid Search | Dense + Sparse + RRF fusion |
| âœ… Year Extraction | Auto-extract from queries |
| âœ… Async | `ainvoke()`, non-blocking |
| âœ… Lifespan DI | Services in `app.state` |
| âœ… Service Layer | RAGService business logic |
| âœ… Custom Exceptions | LLMException, VectorStoreException |
| âœ… Retry Logic | Tenacity with exponential backoff |
| âœ… Docker Ready | Compose for prod/dev |

## ğŸš€ Quick Start

### 1. Setup
```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 2. Configure
```bash
copy .env.example .env
# Edit .env with your Google API key
```

### 3. Start Qdrant
```bash
docker run -p 6333:6333 qdrant/qdrant
```

### 4. Run API
```bash
uvicorn src.main:app --reload
```

Visit: http://localhost:8000/docs

## ğŸ“¡ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/ask` | POST | RAG query |
| `/api/v1/health` | GET | Health check |
| `/docs` | GET | Swagger UI |

### Example Request
```bash
Invoke-RestMethod -Uri "http://localhost:8000/api/v1/ask" `
  -Method POST -ContentType "application/json" `
  -Body '{"question": "2023 NTT DATA sustainability"}'
```

### Example Response
```json
{
  "answer": "NTT DATA's 2023 sustainability report...",
  "sources": ["doc1.pdf", "doc2.pdf"],
  "rewritten_question": "NTT DATA sustainability strategy 2023",
  "years_extracted": [2023]
}
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Application                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Lifespan                          â”‚    â”‚
â”‚  â”‚  Services initialized ONCE at startup:              â”‚    â”‚
â”‚  â”‚  â€¢ LLMService      â€¢ VectorStore                    â”‚    â”‚
â”‚  â”‚  â€¢ EmbeddingService â€¢ RAGService                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                  â”‚
â”‚                    stored in app.state                       â”‚
â”‚                           â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   API Layer                          â”‚    â”‚
â”‚  â”‚  /ask â”€â”€â–º dependencies.py â”€â”€â–º RAGService.ask()      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â”‚                                  â”‚
â”‚                    await ainvoke()                           â”‚
â”‚                           â–¼                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                 LangGraph Workflow                   â”‚    â”‚
â”‚  â”‚  [Rewrite] â”€â”€â–º [Retrieve] â”€â”€â–º [Generate]            â”‚    â”‚
â”‚  â”‚   â€¢ Turkishâ†’EN   â€¢ Hybrid search  â€¢ LLM response    â”‚    â”‚
â”‚  â”‚   â€¢ Year extract â€¢ RRF fusion     â€¢ Context-based   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Design Patterns

| Pattern | Implementation |
|---------|----------------|
| **Dependency Injection** | Lifespan + `app.state` |
| **Service Layer** | `RAGService` orchestrates workflow |
| **Interface Segregation** | `BaseLLMService`, `BaseVectorStore` |
| **Async/Await** | `graph.ainvoke()` for non-blocking |

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ dependencies.py      # DI: get_rag_service()
â”‚   â””â”€â”€ v1/endpoints/
â”‚       â”œâ”€â”€ rag.py           # POST /ask
â”‚       â””â”€â”€ health.py        # GET /health
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py            # Pydantic Settings
â”‚   â”œâ”€â”€ interfaces.py        # ABCs
â”‚   â”œâ”€â”€ exceptions.py        # Custom exceptions
â”‚   â”œâ”€â”€ prompts.py           # YAML prompt loader
â”‚   â”œâ”€â”€ logging_config.py    # Logging configuration
â”‚   â””â”€â”€ state.py             # GraphState TypedDict
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py           # Pydantic models for API
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ rag_service.py       # Business logic layer
â”‚   â”œâ”€â”€ llm.py               # Gemini with retry
â”‚   â”œâ”€â”€ embeddings.py        # Dense + Sparse
â”‚   â””â”€â”€ vector_store.py      # Qdrant hybrid search
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ nodes/               # Rewrite, Retrieve, Generate
â”‚   â””â”€â”€ graph.py             # LangGraph assembly
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompts.yaml         # LLM prompts
â””â”€â”€ main.py                  # Lifespan, app creation

scripts/
â”œâ”€â”€ convert_pdfs.py          # PDF to Markdown converter
â””â”€â”€ ingest_data.py           # Data ingestion pipeline

notebooks/
â”œâ”€â”€ chunking_experiments.ipynb  # Chunking strategy experiments
â”œâ”€â”€ data_analyze.ipynb         # Data analysis and exploration
â””â”€â”€ ocr_test.ipynb             # OCR testing
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src
```

## ğŸ“Š Data Ingestion

The project includes scripts for data preparation and ingestion:

### PDF Conversion
Convert PDF documents to Markdown format:
```bash
python scripts/convert_pdfs.py --input <pdf_file_or_dir> --output <output_dir>
```

### Data Ingestion
Ingest processed documents into the vector database:
```bash
python scripts/ingest_data.py
```

## ğŸ““ Notebooks

Experimental notebooks for analysis and testing:

| Notebook | Description |
|----------|-------------|
| `chunking_experiments.ipynb` | Test different chunking strategies |
| `data_analyze.ipynb` | Analyze and explore document data |
| `ocr_test.ipynb` | Test OCR capabilities |

## ğŸ”§ Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `LLM_API_KEY` | Required | Google API key for LLM |
| `EMBEDDING_API_KEY` | Required | Google API key for embeddings |
| `QDRANT_URL` | http://localhost:6333 | Qdrant server URL |
| `QDRANT_COLLECTION_NAME` | ntt_hybrid_experiment | Vector collection name |
| `LLM_MODEL` | gemini-2.5-flash | LLM model name |
| `EMBEDDING_MODEL` | models/embedding-001 | Embedding model name |
| `LLM_TEMPERATURE` | 0.7 | LLM temperature setting |
| `RAG_K` | 5 | Number of results to retrieve |
| `LOG_LEVEL` | INFO | Logging level |
| `APP_HOST` | 127.0.0.1 | API server host |
| `APP_PORT` | 8000 | API server port |

## ğŸ³ Docker

```bash
# Development (hot reload)
docker-compose -f docker-compose.dev.yaml up

# Production
docker-compose up -d
```

## ğŸ“ License

Internal NTT DATA project

---

**Status**: âœ… Production Ready | **Tests**: All Passing | **Architecture**: Async + LangGraph
